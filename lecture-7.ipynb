{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы Юстины Ивановой: https://github.com/yustinaivanova/netology_statistics_february_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qB1egUSX0gH-"
   },
   "source": [
    "# Кейс-стади -2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01apPJT-zhCm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "from scipy.stats import pearsonr\n",
    "import ssl\n",
    "# следующая строчка подключает сертификат для защищенного соединения\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UB_povh6hYuU"
   },
   "source": [
    "# Байесовский метод решения задачи классификации.\n",
    "\n",
    "Лучшим другом аналитика данных является теорема Байеса, которая позволяет \"переставить\" условные вероятности местами. Пусть нужно узнать вероятность не коего события E, зависящего от наступления некоего другого события F, причем в наличии имеется лишь информация о вероятности события F, зависящего от наступления события E. Двукратное применение (в силу симметрии) определения условной вероятности даст формулу Байеса:\n",
    "\n",
    "\n",
    "$$P(A\\mid B) = \\frac{P(B\\mid A) P(A)}{P(B)}$$\n",
    "\n",
    "где $P(A\\mid B)$ - вероятность наступления события A при условии наличия события B\n",
    "\n",
    "\n",
    "Если событие B разложить на два взаимоисключающих события B при условии A и B при условии $\\bar{A}$, то событие P(B) можно представить как сумма вероятностей наступления событий $P(B\\mid A)$ и  $P(B\\mid \\bar{A})$, тогда формула вероятности примет вид:\n",
    "\n",
    "$$P(A\\mid B) = \\frac{P(B\\mid A) P(A)}{P(B\\mid A)P(A) + P(B\\mid \\bar{A})P(\\bar{A})}$$\n",
    "\n",
    "\n",
    "Если события независимы:\n",
    "\n",
    "$$P(A\\mid B) = P(A)P(B)$$\n",
    "\n",
    "Если события зависимы, и при этом вероятность B не равна нулю, то \n",
    "\n",
    "$$P(A\\mid B) = \\frac{P(A, B) }{P(B)}$$\n",
    "\n",
    "\n",
    "Под этим подразумевается вероятность наступления события A при условии, что известно о наступлении события B.\n",
    "\n",
    "В случае независимости двух переменных формула принимает вид:\n",
    "\n",
    "$$P(A\\mid B) = P(A)$$\n",
    "\n",
    "\n",
    "означает, что наличие наступления события B не дает нам никакой информации о наступлении события A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача. \n",
    "**Определить есть ли болезнь сердца у пациента с определенными показателями.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет больных сердечно-сосудистыми заболеваниями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Источник: https://www.kaggle.com/sulianova/cardiovascular-disease-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data description\n",
    "There are 3 types of input features:\n",
    "\n",
    "Objective: factual information;\n",
    "Examination: results of medical examination;\n",
    "Subjective: information given by the patient.\n",
    "Features:\n",
    "\n",
    "Age | Objective Feature | age | int (days)\n",
    "Height | Objective Feature | height | int (cm) |\n",
    "Weight | Objective Feature | weight | float (kg) |\n",
    "Gender | Objective Feature | gender | categorical code |\n",
    "Systolic blood pressure | Examination Feature | ap_hi | int |\n",
    "Diastolic blood pressure | Examination Feature | ap_lo | int |\n",
    "Cholesterol | Examination Feature | cholesterol | 1: normal, 2: above normal, 3: well above normal |\n",
    "Glucose | Examination Feature | gluc | 1: normal, 2: above normal, 3: well above normal |\n",
    "Smoking | Subjective Feature | smoke | binary |\n",
    "Alcohol intake | Subjective Feature | alco | binary |\n",
    "Physical activity | Subjective Feature | active | binary |\n",
    "Presence or absence of cardiovascular disease | Target Variable | cardio | binary |\n",
    "All of the dataset values were collected at the moment of medical examination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>99993</td>\n",
       "      <td>19240</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>76.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>99995</td>\n",
       "      <td>22601</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>126.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>99996</td>\n",
       "      <td>19066</td>\n",
       "      <td>2</td>\n",
       "      <td>183</td>\n",
       "      <td>105.0</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>99998</td>\n",
       "      <td>22431</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>72.0</td>\n",
       "      <td>135</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>99999</td>\n",
       "      <td>20540</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>72.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  \\\n",
       "69995  99993  19240       2     168    76.0    120     80            1     1   \n",
       "69996  99995  22601       1     158   126.0    140     90            2     2   \n",
       "69997  99996  19066       2     183   105.0    180     90            3     1   \n",
       "69998  99998  22431       1     163    72.0    135     80            1     2   \n",
       "69999  99999  20540       1     170    72.0    120     80            2     1   \n",
       "\n",
       "       smoke  alco  active  cardio  \n",
       "69995      1     0       1       0  \n",
       "69996      0     0       1       1  \n",
       "69997      0     1       0       1  \n",
       "69998      0     0       0       1  \n",
       "69999      0     0       1       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=\"http://yustiks.ru/dataset/cardio_train.csv\"\n",
    "data=pd.read_csv(url,sep=\";\")\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько человек в таблице всего:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Визуализируем несколько взаимосвязей между переменными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взаимосвязь между переменной weight и ap_hi {Systolic blood pressure}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD3CAYAAAD10FRmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAdwElEQVR4nO3df5RcZZ3n8XdVddJNmE43LqGjs5Bml/CdrHtACUNGkw45h0hsIzLD7NnJeNCj7ChMMirKCBiRoMPEYcbggpJhQFkcd7I/BDkK2hKUGWxykLhMgEHbbyAY8Qx0C0gnLaF7uqtr/6hbTXXlVnVV3a6u27mf119VTz1V/a3qqk8996nn3pvK5XKIiEiypJtdgIiIzD2Fv4hIAin8RUQSSOEvIpJACn8RkQRqaXYB1ZqcnMxls/FcmZTJpIhrbaD6olJ90ai+6KLUuGBB5iVgSWn7vAn/bDbH8PCRZpcRqrNzUWxrA9UXleqLRvVFF6XGJUvafxHWrmkfEZEEUviLiCSQwl9EJIEU/iIiCaTwFxFJoHmz2kfmn76BIXb2H2RoZIyu9lY293TTu6Kr2WWJCFWGv5mtAm5w93VmdhJwO3ACkAHe7+4HzOxDwKXABHC9u99nZicCu4DjgOeBD7r7kbC+s/7MpKn6BobYvvtpRicmARgcGWP77qcB9AUgEgMzTvuY2ZXAV4C2oOmvgX9w97XANcDvmNlS4KPAamAD8HkzawWuBXa5ew+wD7i0Ql85huzsPzgV/AWjE5Ps7D/YnIJEZJpqRv4HgIuArwfXVwNPmtn3gYPAx4DzgD3uPgaMmdkzwBnAGmB7cL++4PKBMn1/XKmITCZFZ+eiGp7a3Mlk0rGtDZpT39DIWNn20lr0+kWj+qKJe33QmBpnDH93v9vMuouauoFX3H29mV0LXAXsBw4V9RkBOoDFRe1hbcXtFWkP3/o1o76u9lYGQ74Autpbj6pFr180qi+auNcHkffwDW2vZ7XPy8C3g8v3AmcDh4Hiv9AODJe0h7UVt8sxZHNPN20t099ebS1pNvd0N6cgEZmmnvB/GHhXcHkt8BNgL9BjZm1m1gGsAJ4C9hT17QX6K/SVY0jvii62nr+cpe2tpICl7a1sPX+5fuwViYl6lnpeAXzFzP6U/PTNe939FTO7mXy4p4FPu/uomV0PfC1Y3fNS0PfVsL6z8mwkVnpXdCnsRWIqNV9O4D4+ns3FdV4u7nOGqi8a1ReN6osu4pz/Y+Sn56fRHr4iIgmk8BcRSSCFv4hIAin8RUQSSOEvIpJACn8RkQRS+IuIJJDCX0QkgRT+IiIJpPAXEUkghb+ISAIp/EVEEkjhLyKSQAp/EZEEUviLiCSQwl9EJIGqOpOXma0CbnD3dUVt7wU+4u5vC65/CLgUmACud/f7zOxEYBdwHPA88EF3PxLWdxafk8yRvoEhdvYfZGhkjK72Vjb3dIeeuatcv7B2oKrHFJFoZgx/M7sSeB/walHbW4H/BqSC60uBj5I/W0wb8LCZPQBcC+xy9zvN7GrgUjP7X2F93X1sVp+ZNFTfwBDbdz/N6MQkAIMjY2zf/TTAtLAu1++Jfz3Ed37yq2ntn+tzUqkU45O5io8pItFVM+1zALiocMXM/h2wHbi8qM85wB53H3P3Q8AzwBnAGuB7QZ8+YH2FvjKP7Ow/OBXcBaMTk+zsP1hVv3ueHDyqfSLHVPBXekwRiW7Gkb+7321m3QBmlgG+CnwCeK2o22LyJ3MvGAE6StrD2orbK8pkUnR2LpqpW1NkMunY1gaNqW9oJHxDbWhkbNrfKtdvsoZTR5c+5lxL4v93Nqm+6BpRY1Vz/kVWAsuBvyU/ZfOfzOy/Aw8C7UX92oFh4HBw+bWQttK+FWWzudieZDnuJ4BuRH1d7a0MhgR7V3vrtL9Vrl86Vf0XQOljzrUk/n9nk+qLLuIJ3EPba1rt4+573f3NwQ+/m4CfuvvlwF6gx8zazKwDWAE8BewB3hXcvRfor9BX5pHNPd20tUx/+7S1pKd+tJ2p3x+csfSo9pYULEinZnxMEYmu1pF/KHcfNLObyYd7Gvi0u4+a2fXA14LVPS8B73X3V8P6zkYdMncKP8DOtDKnUr8zf7tDq31EmiSVy9Uw+dpE4+PZXFw3zeK+2aj6olF90ai+6CJO+zxGfnXlNNrJS0QkgRT+IiIJpPAXEUkghb+ISALNymofkSi+/cTz/M39Pu9W+FR7bCOROFL4S1P1DQyx/YGnGR2vfIyguKn22EYicaVpH2mqnf0Hp4K/YD4cz6faYxuJxJXCX5qq0jGC4my+1i1SoPCXpupqb62pPS7ma90iBQp/aarNPd20LZj5GEFxU+2xjUTiSj/4SlP1ruji+EWt8261T7XHNhKJK4W/NN17znwTa5d1NruMmvWu6FLYy7ylaR8RkQRS+IuIJJDCX0QkgRT+IiIJpPAXEUmgqlb7mNkq4AZ3X2dmbwG+BGSBMeD97j4UnKrxUmACuN7d7zOzE4FdwHHA88AH3f1IWN9Zf2YiIlLWjCN/M7sS+ArQFjTdBHwkOIn7N4GrzGwp8FFgNbAB+LyZtQLXArvcvQfYB1xaoa+IiMyRakb+B4CLgK8H1ze5+wtF9x8FzgH2uPsYMGZmzwBnAGuA7UHfvuDygTJ9f1ypiEwmRWfnoqqf2FzKZNKxrQ1UX1SqLxrVF10japwx/N39bjPrLrr+AoCZvR34M2At+RH8oaK7jQAdwOKi9rC24vaKstlcbE+yHPcTQKu+aFRfNKovuogncA9tr+sHXzP7I+BWYKO7vwgcBor/QjswXNIe1lbcLiIic6TmwzuY2cXkf6xd5+6/Dpr3An9pZm1AK7ACeArYA7wLuBPoBfor9BWZRmfKEmmcmkb+ZpYBbiY/Wv+mmf2TmX3W3QeD9n7gQeDT7j4KXA9sMrM9wNuAL1foKzKlcKaswZExcrx+pqy+gaFmlyZyTEjlcrlm11CV8fFsLq7zcnGfM5yP9V1w26MMhpwYZWl7K/d+eNVclQbMz9cvTlRfdBHn/B8Dzi5t105eEks6U5ZIYyn8JZZ0piyRxlL4SyzpTFkijaWTuUjdGrkaR2fKEmkshb/UpbAaZ3RiEnh9NQ4wq18ACnuRxtC0j9RlZ//BqeAvGJ2YZGf/weYUJCI1UfhLXbQaR2R+U/hLXbQaR2R+U/hLXbQaR2R+0w++UhetxhGZ3xT+UjetxhGZvzTtIyKSQAp/EZEEUviLiCSQwl9EJIEU/iIiCVTVah8zWwXc4O7rzOw08qdlzJE//eIWd580s23ARmACuNzd99bSd5afl4iIVDDjyN/MrgS+ArQFTTcC17h7D5ACLjSzs4BzgVXAJuCWOvqKiMgcqWba5wBwUdH1lcBDweU+YD2wBtjt7jl3fw5oMbMlNfYVEZE5MuO0j7vfbWbdRU0pdy+c+HcE6AAWAy8X9Sm019L3xUp1ZDIpOjsXzVRuU2Qy6djWBqovKtUXjeqLrhE11rOHb/FxfNuBYeBwcLm0vZa+FWWzudieZDnuJ4BWfdGovmhUX3QRT+Ae2l7Pap99ZrYuuNwL9AN7gA1mljazU4C0u79UY18REZkj9Yz8rwBuN7OFwABwl7tnzawfeIT8F8qWOvqKiMgcSeVyuZl7xcD4eDYX102zuG82qr5oVF80qi+6iNM+jwFnl7ZrJy8RkQRS+IuIJJDCX0QkgRT+IiIJpPAXEUkghb+ISAIp/EVEEkjhLyKSQAp/EZEEUviLiCSQwl9EJIEU/iIiCaTwFxFJIIW/iEgCKfxFRBJI4S8ikkAKfxGRBKrnNI6Y2QLga0A3kAU+BEwAdwI54Clgi7tPmtk2YGNw++XuvtfMTgvrG+mZiIhI1eod+b8LaHH3twOfA/4SuBG4xt17gBRwoZmdBZwLrAI2AbcE9z+qb/1PQUREalXXyB/YD7SYWRpYDIwDvwc8FNzeB5wPOLDb3XPAc2bWYmZLgJUhfe+p9AczmRSdnYvqLLexMpl0bGsD1ReV6otG9UXXiBrrDf/fkJ/y+RlwIvBuYG0Q8gAjQAf5L4aXi+5XaE+F9K0om83F9iTLcT8BtOqLRvVFo/qii3gC99D2eqd9Pg7c7+6nA2eSn/9fWHR7OzAMHA4ul7ZPhrSJiMgcqTf8XwEOBZd/DSwA9pnZuqCtF+gH9gAbzCxtZqcAaXd/qUxfERGZI/VO+3wRuMPM+smP+LcC/w+43cwWAgPAXe6eDfo8Qv6LZktw/ytK+0Z4DiIiUqO6wt/dfwP815Cbzg3pex1wXUnb/rC+IiIyN7STl4hIAin8RUQSSOEvIpJACn8RkQRS+IuIJJDCX0QkgRT+IiIJpPAXEUkghb+ISAIp/EVEEkjhLyKSQAp/EZEEUviLiCSQwl9EJIEU/iIiCaTwFxFJoHrP5IWZfQp4D/kzee0EHgLuBHLAU8AWd580s23ARmACuNzd95rZaWF9IzwPERGpQV0j/+D8u28HVpM/I9fJwI3ANe7eA6SAC83srOD2VcAm4JbgIY7qG+E5iIhIjeqd9tkA/AtwD3AvcB+wkvzoH6APWA+sAXa7e87dnwNazGxJmb4iIjJH6p32ORFYBrwbOBX4NpB291xw+wjQASwGXi66X6E9FdK3okwmRWfnojrLbaxMJh3b2kD1RaX6olF90TWixnrD/2XgZ+7+b4Cb2Sj5qZ+CdmAYOBxcLm2fDGmrKJvNMTx8pM5yG6uzc1FsawPVF5Xqi0b1RRelxiVL2kPb6532eRh4p5mlzOxNwPHAD4LfAgB6gX5gD7DBzNJmdgr5rYOXgH0hfUVEZI7UNfJ39/vMbC2wl/wXyBbg58DtZrYQGADucvesmfUDjxT1A7iitG+0pyEiIrVI5XK5mXvFwPh4NhfXTbO4bzaqvmhUXzSqL7qI0z6PAWeXtmsnLxGRBFL4i4gkkMJfRCSBFP4iIgmk8BcRSSCFv4hIAin8RUQSSOEvIpJACn8RkQRS+IuIJJDCX0QkgRT+IiIJpPAXEUkghb+ISAIp/EVEEkjhLyKSQAp/EZEEqvcE7gCY2UnAY8A7gAngTiAHPAVscfdJM9sGbAxuv9zd95rZaWF9o9QiIiLVq3vkb2YLgL8DXguabgSucfceIAVcaGZnAecCq4BNwC3l+tZbh4iI1C7KyP8LwK3Ap4LrK4GHgst9wPmAA7vdPQc8Z2YtZrakTN97Kv2xTCZFZ+eiCOU2TiaTjm1toPqiUn3RqL7oGlFjXeFvZh8AXnT3+82sEP6pIOQBRoAOYDHwctFdC+1hfSvKZnOxPcly3E8ArfqiUX3RqL7oIp7APbS93pH/JUDOzNYDbwH+Hjip6PZ2YBg4HFwubZ8MaRMRkTlS15y/u69193PdfR3wOPB+oM/M1gVdeoF+YA+wwczSZnYKkHb3l4B9IX1FRGSORFrtU+IK4HYzWwgMAHe5e9bM+oFHyH/RbCnXdxbrEBGRGUQO/2D0X3BuyO3XAdeVtO0P6ysiInNDO3mJiCSQwl9EJIEU/iIiCaTwFxFJIIW/iEgCKfxFRBJI4S8ikkAKfxGRBFL4i4gkkMJfRCSBFP4iIgmk8BcRSSCFv4hIAin8RUQSSOEvIpJACn8RkQSq9wTuC4A7gG6gFbge+ClwJ5ADngK2uPukmW0DNgITwOXuvtfMTgvrG+mZyLzSNzDEzv6DDI2M8caONi5bvYzeFV3NLkskMeod+V8MvOzuPcA7gS8DNwLXBG0p4EIzO4v8GbtWAZuAW4L7H9W3/qcg803fwBDbdz/N4MgYOeD5Q6Ns3/00fQNDzS5NJDHqDf9vAJ8JLqfIj+pXAg8FbX3AemANsNvdc+7+HNBiZkvK9JWE2Nl/kNGJ6Rt6oxOT7Ow/2JyCRBKormkfd/8NgJm1kz/5+jXAF9w9F3QZATqAxcDLRXcttKdC+laUyaTo7FxUT7kNl8mkY1sbxK++oZGxsu1xqrMgbq9fKdUXTdzrg8bUWPcJ3M3sZOAeYKe77zKzvy66uR0YBg4Hl0vbJ0PaKspmcwwPH6m33Ibq7FwU29ogfvV1tbcyGPIF0NXeGqnO4t8Rutpb2dzTPSu/I8Tt9Sul+qKJe30QrcYlS9pD2+ua9jGzLmA3cJW73xE07zOzdcHlXqAf2ANsMLO0mZ0CpN39pTJ9JSE293TT1jL9rdfWkmZzT3fdj1n6O8LgyJh+RxCpoN6R/1bgBOAzZlaY+/8YcLOZLQQGgLvcPWtm/cAj5L9otgR9rwBuL+5b7xOQ+aF0VL7xzSex59lXZm21T6XfEbSKSORoqVwuN3OvGBgfz+biumkW983GRtfXNzDEjgcPcGh0AoDFrRn+/LzTpkK3MCovDue2lvTUF8DgyBjpFEzmoKOthVwux8hYNnTqptzUzjk7fkjYOzkF7L1ibaTnl/T/b1SqL7qI0z6PAWeXttc95y/JUi50+waG+Ivv7Wd88vXoPTyW5XN9DkDviq6yo/K7nxicul64e+ELBF6fuik8TumXSPHtlX5HEJGjKfylrELgl4Zqceju7D84LfgLJnJwXZ+z7bseOiKvVvHUTaWpnc093aFbF1F+RxA5lin8JVTYVE2xQuiWW7YJr4/moyr8jUpLRAtTQ41Y7SNyLFL4S6iwUXapwZExFrdmODyWbWgti9vyb9OZpnZ6V3Qp7EWqpAO7JVTfwBAX3PYo5+z4IRfc9uhRSyIrjeiLvTY+2fA3UWFRQiOWiIoklUb+80C9Oy9V+pG23A+nhcdd3NYy7cfXcsLm+1MQOs/f0dbC2MRk6BZFYbVPmMNjWS647VE293Sz9fzldU/tNGonMJH5SOEfc6WraQZHxviL7+0HqBhclQJ+pjXxfQNDjFQR/KVaUnBtr/HEvx6atpKnYL2dyJm/3XFUAP/x205lePgI5315T9kppEL9W89fzr0fXlVzbdV84YkkicI/5nY8eOCo0fX4ZI4dDx6oGFqVAr7SD6eF+9ZzfO2JHBUPzrbn2Ve4ev3pZetOpVIVHz/KTlvaCUxkOoV/zJWbeplpSqZSwM/0w2m18/21/N1qHvdwFVsblR6j0rTOTF94IkmjH3yPUeV2biqEYqUfTqPsGNXV3lrxb89032oeP8xMx/aptyaRY5XCP+YWt2Zqai+oFPC9K7rYev5ylra3kgKWtrey9fzlU6PkzT3dLEgfPQWTgtD2gpZU/r71rsoJu1+1jzHTOQK0UkhkOk37xNyfn3can+tzJoqm/VtS+fZKZtrpqdKa+EJ72PF6Co85ODI2bVVPWyZF64IM277rRx24rdqVNaU1L57hOD/FZprW0U5gItMp/GOuWaFVzZdDQWHKpfBFMTgyxnd+8qtpWxOz8XcrqebYPtoJTOR1Cv95oJ7Qmmlp40xr3ktvX/0fTig7ki835XLtd31q66F4K2Fxa4Z3/M4SvvnE4FH7A6RT8AdnLOXq9aeHPq+/+v5+7nlycGqfgOMWpHltfJJyk1G1TusUH88obH+Fwv4IS4tek+Kjki5uzZBKpTg0OjGtb6GO4q2pwtbS4dGJRGyJaD+LeDmmD+lc/EEu/SDO5ptupsOt9g0M8YUfPDO1hr0QKuV2hhKRcNV+ZtIpWHZCG794ZZTJXPigImyA88DPXqx4uJJG5EclxYOdmQZG5ZQ7pPMxG/6VDkzW1pKuaUqi9Hj1BYU3QmEnpULfsCNhikjzFb48OtpaeHVsYtpvabVq9BfBX31/f+jOkn94Zm1fALE7nr+ZpYGdwJnAGPAn7v7MbD1+pQOT1bJzT9jx6gsKUynHL2pl7bLOGY+EKSLNVfgUV3Pokpk0ei/xe548OvgL7bWO/sM0c6nn7wNt7v424Gpgx2w++Ew771S7c0+549UXjE5MsuOB/VN9FfwiyVG8nHi2lYud2TpUejPDfw3wPQB3/xEhmyVRzMYORVDdl8QLh0ar7isix5ZGfe7L7VJTYVebmjRztc9i4FDR9ayZtbh76PZYJpOis3NR1Q/+yQ3Gp7/1FKPjIXP+C9J8coNV9Xhv7Gjj+SDcy/bpbKOzc1FVfUXk2PLGjraasqlam373ZHbt/WVo+2z8vWaG/2Ggveh6ulzwA2SzuZpOYLx2WSdb37G87Gqftcs6q3q8y1YvKzvnD/kfj69YfzrDw0e4bPUyzfmLzBML0imOW5Ce2onwuAUpfv7r2gZvbS1pLlu9rCEngP94z6mMjY0ftdrn4z2n1vT3lixpD21vZvjvAS4A/q+Z/R7wL7P9B2Zjp56wvV0LCl8k7znzTQwPH5m27l2rfWQ+qnYpZVsmxVg2N9X3uJYUnzr/9SO29g0M8fnd+3ktWE6TAi46c+m0Q3q3Fj1G6TLG4mWY7SH7ThzXkpp67IJT39DGiccv5Me/PFz2eYUt+S5eqj3T0sq53lfh6vWnc/X602dcTl6Ppi31LFrtcwb5/80H3f1n5frXs85/rjTiH1ONSm/EC257VF9AIY5rSbGwJXPUjmcFKZgKpZYUjBd1OPUNbbw2nps69MS/TWSnAqhw+ItKO8qVBsVsrOGG5r3/qqX6ootSY+LW+c+lOL55wpadFu/fUCmYZmt9cT21wewdymK2Rmlx/P8WU33RxL0+aEz46/AOx6goB3YrBPxsjEqrqe2NHW1ctnrZtNpm6+/o8AEi4TTynwVxHzmovmhUXzSqL7pGjPx1PH8RkQRS+IuIJJDCX0QkgRT+IiIJpPAXEUmgebPaB3gR+EWzixARmWeWAUtKG+dT+IuIyCzRtI+ISAIp/EVEEkjhLyKSQAp/EZEEUviLiCSQwl9EJIF0SOcamdkC4A6gG2gFrgd+CdwHPB10+1t3/z9NKRAws38mf5pMgJ8DfwfcBEwAu939s02s7QPAB4KrbcBbgD8GvkD+dQTY5u4PNaG2VcAN7r7OzE4D7iR/vpengC3uPmlm24CN5F/Ly919b5PqewvwJSALjAHvd/chM7sJWAOMBHe70N0PhT9iQ+t7KyGfiRi9fv8bWBrc1A38yN03mdm3gBOBceA1d++do9rCcuWnNPA9qPCv3cXAy+7+PjN7A/A48DngRnff0dzSwMzagJS7rytqexz4Q+BZ4Dtm9lZ339eM+tz9TvJvaMzsFvJv+JXAle5+dzNqCmq5Engf8GrQdCNwjbv/k5ndClxoZr8AzgVWAScDdwO/26T6bgI+4u6Pm9mlwFXAJ8i/lhvc/aW5qKtCfSsp+UyY2VnE5PVz901B+wnAPwIfD7ouB97s7nO9A1RYrjxOA9+Dmvap3TeAzwSXU+S/fVcCG83sh2b2VTMLP2Py3DgTWGRmu83sQTNbC7S6+4HgDX0/sL6J9QFgZmeT/5DdRv71u8TM+s1sh5k1Y1ByALio6PpKoLD10Uf+NVtDfssp5+7PAS1mdtSek3NU3yZ3fzy43AKMBqdGXQ7cZmZ7zOySOaotrL6wz0ScXr+CzwJfcvcXzKwL6ATuNbOHzezdc1QblM+Vhr0HFf41cvffuPtI8Ga+C7gG2At80t3Xkh9db2tiiUfIT6FsAC4D/kfQVjACdDShrlJbyX/wAB4APgKsBX6LfN1zKtjqGC9qShWN/gqv2WKgeAplzl7L0vrc/QUAM3s78GfAF4HjyU8FXQy8E9hsZmc0oz7CPxOxef0AzOwk4DyCLVFgIbAD+H3yXxRfDPrMRX1hudLQ96DCvw5mdjL5TcWvu/su4B53fyy4+R7grU0rDvYD/zMYGewn/0Z5Q9Ht7cBwUyoLmFknYO7+j0HTHe7+bPBG/xbNff0KJosuF16zw8Hl0vamMLM/Am4FNrr7i+S/5G9y9yPuPgI8SH5LsBnCPhOxev2A/wLscvdscH0QuNXdJ9z9V8A+wOaqmJBcaeh7UOFfo2DTcDdwlbvfETTfb2bnBJfPAx4LvfPcuIT86AUzexOwCHjVzP6jmaXIbxH0N7E+yI/wfwAQ1PSkmf374LZmv34F+8xsXXC5l/xrtgfYYGZpMzsFSM/13HqBmV1MfsS/zt2fDZpPB/aYWSb4AXEN8M/NqI/wz0RsXr/AevLTKcXXvwFgZr8F/GdgYC4KKZMrDX0P6gff2m0FTgA+Y2aFObpPkN9EHCc/evhws4oDvgrcaWYPk18lcAn5EcQ/ABny84WPNrE+yI+mngVw95yZ/QnwTTN7jfwKh9ubWVzgCuB2M1tIPgDucvesmfUDj5AfOG1pRmFmlgFuBp4j/7oBPOTu28zs68CPyE9x/L27/6QZNQJ/Cnyp+DPh7ofj8PoVmXofArh7n5ltMLMfkf/MbJ3DL6ewXPkYcHOj3oM6qqeISAJp2kdEJIEU/iIiCaTwFxFJIIW/iEgCKfxFRBJI4S8ikkAKfxGRBPr/L/5Aujq5sG0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data.weight, data.ap_hi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем взаимосвязь между  weight и ap_lo {Diastolic blood pressure}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data.weight, data.ap_lo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем зависимость между ap_hi {Systolic blood pressure} и ap_lo {Diastolic blood pressure}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data.ap_hi, data.ap_lo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# С использованием t-test статистики проверим взаимосвязи между несколькими переменными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как тестировать две переменные, как посчитать степени свободы: https://towardsdatascience.com/inferential-statistics-series-t-test-using-numpy-2718f8f9bf2f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-2079.746249421458, pvalue=0.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(data.weight, data.age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value < 0.05, поэтому можно сказать что имеется статистическое различие между атрибутами. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека researchpy: pip install researchpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>SE</th>\n",
       "      <th>95% Conf.</th>\n",
       "      <th>Interval</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cardio</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35021</td>\n",
       "      <td>1.345707</td>\n",
       "      <td>0.475605</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>1.340726</td>\n",
       "      <td>1.350688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34979</td>\n",
       "      <td>1.353441</td>\n",
       "      <td>0.478045</td>\n",
       "      <td>0.002556</td>\n",
       "      <td>1.348431</td>\n",
       "      <td>1.358451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            N      Mean        SD        SE  95% Conf.  Interval\n",
       "cardio                                                          \n",
       "0       35021  1.345707  0.475605  0.002541   1.340726  1.350688\n",
       "1       34979  1.353441  0.478045  0.002556   1.348431  1.358451"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import researchpy as rp\n",
    "# Showing descriptive statistics from researchpy.summary_cont()\n",
    "rp.summary_cont(data.groupby('cardio')['gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N - количество элементов\n",
    "Mean - среднее значение\n",
    "SD - стандартное отклонение\n",
    "SE - стандартная ошибка (https://ru.wikipedia.org/wiki/Стандартная_ошибка)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для подсчета t-test: https://researchpy.readthedocs.io/en/latest/ttest_documentation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>N</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>SE</th>\n",
       "      <th>95% Conf.</th>\n",
       "      <th>Interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cardio</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>0.499700</td>\n",
       "      <td>0.500003</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.495996</td>\n",
       "      <td>0.503404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weight</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>74.205690</td>\n",
       "      <td>14.395757</td>\n",
       "      <td>0.054411</td>\n",
       "      <td>74.099045</td>\n",
       "      <td>74.312335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>combined</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>37.352695</td>\n",
       "      <td>38.234750</td>\n",
       "      <td>0.102187</td>\n",
       "      <td>37.152411</td>\n",
       "      <td>37.552979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variable         N       Mean         SD        SE  95% Conf.   Interval\n",
       "0    cardio   70000.0   0.499700   0.500003  0.001890   0.495996   0.503404\n",
       "1    weight   70000.0  74.205690  14.395757  0.054411  74.099045  74.312335\n",
       "2  combined  140000.0  37.352695  38.234750  0.102187  37.152411  37.552979"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptives, results = rp.ttest(data.cardio, data.weight)\n",
    "\n",
    "descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Independent t-test</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Difference (cardio - weight) =</td>\n",
       "      <td>-73.7060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Degrees of freedom =</td>\n",
       "      <td>139998.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t =</td>\n",
       "      <td>-1353.8031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two side test p value =</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Difference &lt; 0 p value =</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Difference &gt; 0 p value =</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cohen's d =</td>\n",
       "      <td>-7.2364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hedge's g =</td>\n",
       "      <td>-7.2363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Glass's delta =</td>\n",
       "      <td>-147.4110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>r =</td>\n",
       "      <td>0.9639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Independent t-test      results\n",
       "0  Difference (cardio - weight) =      -73.7060\n",
       "1            Degrees of freedom =   139998.0000\n",
       "2                             t =    -1353.8031\n",
       "3         Two side test p value =        0.0000\n",
       "4        Difference < 0 p value =        0.0000\n",
       "5        Difference > 0 p value =        1.0000\n",
       "6                     Cohen's d =       -7.2364\n",
       "7                     Hedge's g =       -7.2363\n",
       "8                 Glass's delta =     -147.4110\n",
       "9                             r =        0.9639"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value < 0.05, поэтому можно сказать что имеется статистическое различие между атрибутами. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference (cardio - weight) = разница между средними двух атрибутов\n",
    "Degrees of freedom = степени свободы для двух атрибутов\n",
    "t = t-value\n",
    "Two side test p value =\tpvalue\n",
    "Difference < 0 p value = pvalue для гипотезы, что разницы между двумя переменными отсутствует\n",
    "Difference > 0 p value = pvalue для гипотезы, что разница между двумя переменными есть\n",
    "Cohen's d = https://researchpy.readthedocs.io/en/latest/ttest_documentation.html#cohen-s-dz-within-subject-design\n",
    "Hedge's g = https://researchpy.readthedocs.io/en/latest/ttest_documentation.html#hedges-s-gs-between-subjects-design\n",
    "Glass's delta = https://researchpy.readthedocs.io/en/latest/ttest_documentation.html#glass-s-delta-between-or-within-subjects-design\n",
    "r = коэффициент корреляции Пирсона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Протестируем гипотезу, что женщины болеют чаще чем мужчины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "female = data[data['gender']==1].cardio\n",
    "male = data[data['gender']==2].cardio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptives, results = rp.ttest(female, male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напечатаем результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Variable        N      Mean        SD        SE  95% Conf.  Interval\n",
      "0    cardio  45530.0  0.496727  0.499995  0.002343   0.492135  0.501320\n",
      "1    cardio  24470.0  0.505231  0.499983  0.003196   0.498966  0.511496\n",
      "2  combined  70000.0  0.499700  0.500003  0.001890   0.495996  0.503404\n",
      "_______________________________________\n",
      "                Independent t-test     results\n",
      "0  Difference (cardio - cardio) =      -0.0085\n",
      "1            Degrees of freedom =   69998.0000\n",
      "2                             t =      -2.1456\n",
      "3         Two side test p value =       0.0319\n",
      "4        Difference < 0 p value =       0.0160\n",
      "5        Difference > 0 p value =       0.9840\n",
      "6                     Cohen's d =      -0.0170\n",
      "7                     Hedge's g =      -0.0170\n",
      "8                 Glass's delta =      -0.0170\n",
      "9                             r =       0.0081\n"
     ]
    }
   ],
   "source": [
    "print(descriptives)\n",
    "print('_______________________________________')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что есть разница между женщинами и мужчинами (pvalue<0.05). Возможно это связано с тем, что женщин в выборке в 2 раза больше чем мужчин."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверим гипотезу о том, что люди с показателем cholesterol = 2 болеют чаще"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chol_2 = data[data['cholesterol']==2].cardio\n",
    "chol_all = data[data['cholesterol']!=2].cardio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Variable        N      Mean        SD        SE  95% Conf.  Interval\n",
      "0    cardio   9549.0  0.602157  0.489478  0.005009   0.592339  0.611976\n",
      "1    cardio  60451.0  0.483516  0.499732  0.002033   0.479532  0.487499\n",
      "2  combined  70000.0  0.499700  0.500003  0.001890   0.495996  0.503404\n",
      "_____________________________\n",
      "                Independent t-test     results\n",
      "0  Difference (cardio - cardio) =       0.1186\n",
      "1            Degrees of freedom =   69998.0000\n",
      "2                             t =      21.6191\n",
      "3         Two side test p value =       0.0000\n",
      "4        Difference < 0 p value =       1.0000\n",
      "5        Difference > 0 p value =       0.0000\n",
      "6                     Cohen's d =       0.2381\n",
      "7                     Hedge's g =       0.2381\n",
      "8                 Glass's delta =       0.2424\n",
      "9                             r =       0.0814\n"
     ]
    }
   ],
   "source": [
    "descriptives, results = rp.ttest(chol_2, chol_all)\n",
    "print(descriptives)\n",
    "print('_____________________________')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p value = 0.0000, то отличие людей с показателем chol = 2 значительное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=21.619123191535245, pvalue=2.5898307558677926e-103)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(chol_2, chol_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значит, люди с показателем chol=2 болеют чаще, чем остальные (среднее значение выборки больше чем остальных)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверим гипотезу о том, что люди, которые курят, болеют чаще сердечной болезнью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Variable        N      Mean        SD        SE  95% Conf.  Interval\n",
      "0    cardio   6169.0  0.474793  0.499405  0.006358   0.462329  0.487258\n",
      "1    cardio  63831.0  0.502107  0.499999  0.001979   0.498228  0.505986\n",
      "2  combined  70000.0  0.499700  0.500003  0.001890   0.495996  0.503404\n",
      "_____________________________\n",
      "                Independent t-test     results\n",
      "0  Difference (cardio - cardio) =      -0.0273\n",
      "1            Degrees of freedom =   69998.0000\n",
      "2                             t =      -4.0976\n",
      "3         Two side test p value =       0.0000\n",
      "4        Difference < 0 p value =       0.0000\n",
      "5        Difference > 0 p value =       1.0000\n",
      "6                     Cohen's d =      -0.0546\n",
      "7                     Hedge's g =      -0.0546\n",
      "8                 Glass's delta =      -0.0547\n",
      "9                             r =       0.0155\n"
     ]
    }
   ],
   "source": [
    "smoke = data[data['smoke']==1].cardio\n",
    "no_smoke = data[data['smoke']==0].cardio\n",
    "descriptives, results = rp.ttest(smoke, no_smoke)\n",
    "print(descriptives)\n",
    "print('_____________________________')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference > 0 p value = 1.0000, значит, различие в двух выборках значительное.  Среднее значение по атрибуту cardio у курящих 0.47, среднее значение среди некурящих 0.50, скорее связано с тем, что выборки имеют разное количество элементов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-4.097626290112295, pvalue=4.1787798766011306e-05)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(smoke, no_smoke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC-кривая"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC-кривая (англ. receiver operating characteristic, рабочая характеристика приёмника) — график, позволяющий оценить качество бинарной классификации, отображает соотношение между долей объектов от общего количества носителей признака, верно классифицированных как несущие признак (англ. true positive rate, TPR, называемой чувствительностью алгоритма классификации), и долей объектов от общего количества объектов, не несущих признака, ошибочно классифицированных как несущие признак (англ. false positive rate, FPR, величина 1-FPR называется специфичностью алгоритма классификации) при варьировании порога решающего правила.\n",
    "\n",
    "Также известна как кривая ошибок. Анализ классификаций с применением ROC-кривых называется ROC-анализом.\n",
    "\n",
    "Количественную интерпретацию ROC даёт показатель AUC (англ. area under ROC curve, площадь под ROC-кривой) — площадь, ограниченная ROC-кривой и осью доли ложных положительных классификаций. Чем выше показатель AUC, тем качественнее классификатор, при этом значение 0,5 демонстрирует непригодность выбранного метода классификации (соответствует случайному гаданию). Значение менее 0,5 говорит, что классификатор действует с точностью до наоборот: если положительные назвать отрицательными и наоборот, классификатор будет работать лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача:  создать модель, предсказывающую наличие болезни по параметрам, заданным в таблице"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>99993</td>\n",
       "      <td>19240</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>76.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>99995</td>\n",
       "      <td>22601</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>126.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>99996</td>\n",
       "      <td>19066</td>\n",
       "      <td>2</td>\n",
       "      <td>183</td>\n",
       "      <td>105.0</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>99998</td>\n",
       "      <td>22431</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>72.0</td>\n",
       "      <td>135</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>99999</td>\n",
       "      <td>20540</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>72.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  \\\n",
       "69995  99993  19240       2     168    76.0    120     80            1     1   \n",
       "69996  99995  22601       1     158   126.0    140     90            2     2   \n",
       "69997  99996  19066       2     183   105.0    180     90            3     1   \n",
       "69998  99998  22431       1     163    72.0    135     80            1     2   \n",
       "69999  99999  20540       1     170    72.0    120     80            2     1   \n",
       "\n",
       "       smoke  alco  active  cardio  \n",
       "69995      1     0       1       0  \n",
       "69996      0     0       1       1  \n",
       "69997      0     1       0       1  \n",
       "69998      0     0       0       1  \n",
       "69999      0     0       1       0  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data.drop(['id', 'cardio'], axis=1), data.cardio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.588076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.579487</td>\n",
       "      <td>0.273684</td>\n",
       "      <td>0.016079</td>\n",
       "      <td>0.013550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517949</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.017934</td>\n",
       "      <td>0.014453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.624003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.284211</td>\n",
       "      <td>0.017316</td>\n",
       "      <td>0.012647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.528455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.378947</td>\n",
       "      <td>0.018553</td>\n",
       "      <td>0.015357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.516918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517949</td>\n",
       "      <td>0.242105</td>\n",
       "      <td>0.015461</td>\n",
       "      <td>0.011743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1         2         3         4         5    6    7    8    9  \\\n",
       "0  0.588076  1.0  0.579487  0.273684  0.016079  0.013550  0.0  0.0  0.0  0.0   \n",
       "1  0.730159  0.0  0.517949  0.394737  0.017934  0.014453  1.0  0.0  0.0  0.0   \n",
       "2  0.624003  0.0  0.564103  0.284211  0.017316  0.012647  1.0  0.0  0.0  0.0   \n",
       "3  0.528455  1.0  0.584615  0.378947  0.018553  0.015357  0.0  0.0  0.0  0.0   \n",
       "4  0.516918  0.0  0.517949  0.242105  0.015461  0.011743  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    10  \n",
       "0  1.0  \n",
       "1  1.0  \n",
       "2  0.0  \n",
       "3  1.0  \n",
       "4  0.0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "np_scaled = min_max_scaler.fit_transform(x)\n",
    "df_norm = pd.DataFrame(np_scaled)\n",
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_norm,y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем модель **Наивный Байес**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of our model: 0.5932857142857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "print(\"the accuracy of our model: {}\".format(nb.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.87      0.68      6988\n",
      "           1       0.71      0.32      0.44      7012\n",
      "\n",
      "    accuracy                           0.59     14000\n",
      "   macro avg       0.64      0.59      0.56     14000\n",
      "weighted avg       0.64      0.59      0.56     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, nb.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our accuracy is: 0.6545714285714286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter = 200)\n",
    "lr.fit(x_train,y_train)\n",
    "print(\"our accuracy is: {}\".format(lr.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.68      0.66      6988\n",
      "           1       0.66      0.63      0.65      7012\n",
      "\n",
      "    accuracy                           0.65     14000\n",
      "   macro avg       0.66      0.65      0.65     14000\n",
      "weighted avg       0.66      0.65      0.65     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lr.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень низкий recall - это может быть связано с **несбалансированностью классов**. Сравним модель **Наивного Байеса** с моделью **Random Forest**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# создаем модель деревья решений\n",
    "# выбираем 100 деревьев в качестве параметра\n",
    "model=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# обучаем модель\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель Random Forest дает лучше результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72      6988\n",
      "           1       0.72      0.70      0.71      7012\n",
      "\n",
      "    accuracy                           0.71     14000\n",
      "   macro avg       0.71      0.71      0.71     14000\n",
      "weighted avg       0.71      0.71      0.71     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_pred = model.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, model_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определение СПАМа в тексте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XvItYzkj6nUK"
   },
   "source": [
    "Датасет для определения СПАМа в тексте.  https://www.kaggle.com/team-ai/spam-text-message-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Df9gsOk36YpQ",
    "outputId": "ddc3a729-c218-494e-9e0a-8e30856a163d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message\n",
       "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568      ham               Will ü b going to esplanade fr home?\n",
       "5569      ham  Pity, * was in mood for that. So...any other s...\n",
       "5570      ham  The guy did some bitching but I acted like i'd...\n",
       "5571      ham                         Rofl. Its true to its name"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='http://yustiks.ru/dataset/SPAM_text.csv'\n",
    "data=pd.read_csv(url) \n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "jvKJuvWXaNqw",
    "outputId": "76fcd9a3-c1a0-4f6b-e98a-76c12f2243e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n"
     ]
    }
   ],
   "source": [
    "print(data.loc[2, 'Message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим новый атрибут Category, где будем указывать, что если данный текст является СПАМом, то 1, если не является, то 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DiBSfYAu7E3J"
   },
   "outputs": [],
   "source": [
    "data[\"Category\"] = [1 if each == \"spam\" else 0 for each in data[\"Category\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "DxJF-FT57GgK",
    "outputId": "3e1a5e9d-4442-4880-e766-7ced24846726"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                            Message\n",
       "0         0  Go until jurong point, crazy.. Available only ...\n",
       "1         0                      Ok lar... Joking wif u oni...\n",
       "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         0  U dun say so early hor... U c already then say...\n",
       "4         0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a9Vu6XzsBfWw"
   },
   "source": [
    "Как на основе текста предсказать, что он является СПАМом? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwcux5EgBqJN"
   },
   "source": [
    "# Словарь BAG-of-words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gAuXKIzSB-82"
   },
   "source": [
    "Создаем слова. На основе слов пишем для каждого текста словарь, где каждое слово - это ключ, а значение ключа - это сколько раз встречается данное слова в данном тексте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zyjsN0ZqPPgn"
   },
   "source": [
    "Как пример: рассмотрим 1 строку из датасета.\n",
    "\n",
    "\n",
    "\n",
    "*   Удалим все символы, не являющимися латинскими буквами\n",
    "*   Заглавные буквы меняем на строчные\n",
    "*   Разделим текст на слова\n",
    "*   В каждом слове выделяем корень слова\n",
    "*   Создаем список всех слов\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "rq4UlSZkNH-E",
    "outputId": "2706c926-e86a-4b89-ad4f-b616c6782465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "nlp_data = str(data.loc[2, 'Message'])\n",
    "print(nlp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0E_4QMsONv3v"
   },
   "source": [
    "Удаление всех не латинских букв:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "yRM_Ykz3NJvK",
    "outputId": "8a8de0e0-e526-4e18-ff00-14cedfac6e45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free entry in   a wkly comp to win FA Cup final tkts   st May       Text FA to       to receive entry question std txt rate T C s apply            over   s\n"
     ]
    }
   ],
   "source": [
    "nlp_data = re.sub(\"[^a-zA-Z]\",\" \", nlp_data)\n",
    "print(nlp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_TIDOgsN-Y_"
   },
   "source": [
    "Во всех словах заглавные буквы меняем на строчные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "qzy8kpblN5aE",
    "outputId": "345d4441-b118-4223-b7d4-94e554191a64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free entry in   a wkly comp to win fa cup final tkts   st may       text fa to       to receive entry question std txt rate t c s apply            over   s\n"
     ]
    }
   ],
   "source": [
    "nlp_data = nlp_data.lower()\n",
    "print(nlp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ibxAPXnOgvj"
   },
   "source": [
    "Переводим текст в отдельные слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "XOhX6nvMOPJD",
    "outputId": "dfbec726-4992-4077-f1d7-e5c92168ccab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['free', 'entry', 'in', 'a', 'wkly', 'comp', 'to', 'win', 'fa', 'cup', 'final', 'tkts', 'st', 'may', 'text', 'fa', 'to', 'to', 'receive', 'entry', 'question', 'std', 'txt', 'rate', 't', 'c', 's', 'apply', 'over', 's']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/yustinaivanova/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk as nlp # библиотека nltk -> pip install nltk \n",
    "nlp.download('punkt')\n",
    "nlp_data = nlp.word_tokenize(nlp_data)\n",
    "print(nlp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5dpudpmrO_Tp"
   },
   "source": [
    "Ищем корень каждого слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "hbPUYfsTOo9o",
    "outputId": "31f936e5-61e1-4e48-8d43-842b52261f4a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/yustinaivanova/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['free', 'entry', 'in', 'a', 'wkly', 'comp', 'to', 'win', 'fa', 'cup', 'final', 'tkts', 'st', 'may', 'text', 'fa', 'to', 'to', 'receive', 'entry', 'question', 'std', 'txt', 'rate', 't', 'c', 's', 'apply', 'over', 's']\n"
     ]
    }
   ],
   "source": [
    "nlp.download('wordnet')\n",
    "lemma = nlp.WordNetLemmatizer()\n",
    "nlp_data = [lemma.lemmatize(word) for word in nlp_data]\n",
    "print(nlp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "40keBPrTCLqB"
   },
   "source": [
    "Добавляем все найденные слова в список"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3O1MxC11PJ70"
   },
   "outputs": [],
   "source": [
    "nlp_data = \" \".join(nlp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aWpIjfZiQk8u"
   },
   "outputs": [],
   "source": [
    "description_list = []\n",
    "for description in data[\"Message\"]:\n",
    "    description = re.sub(\"[^a-zA-Z]\",\" \",description)\n",
    "    description = description.lower()\n",
    "    description = nlp.word_tokenize(description)\n",
    "    lemma = nlp.WordNetLemmatizer()\n",
    "    description = [ lemma.lemmatize(word) for word in description]\n",
    "    description = \" \".join(description)\n",
    "    description_list.append(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько всего получилось слов в словаре мешка слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Yb7nm-_YcDQd",
    "outputId": "3fe4bd78-1d3c-498e-ab4c-7e18bd161733"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(description_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xloAtHs2dw3U",
    "outputId": "a459b93e-4ccf-401c-9afc-09c02c66a941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n"
     ]
    }
   ],
   "source": [
    "print(description_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZBGlFp0Q2NW"
   },
   "source": [
    "Создаем bag-of-words, для этого выбираем 3000 максимально встречаемых слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "uH0OST_KQ4gj",
    "outputId": "45c24f21-fb14-4016-b4fc-1dc0dc8cd90f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Самые часто встречаемые 3000 слов: ['aah', 'aathi', 'abi', 'ability', 'abiola', 'abj', 'able', 'absolutly', 'abt', 'abta', 'aburo', 'ac', 'academic', 'acc', 'accept', 'access', 'accident', 'accidentally', 'accordingly', 'account', 'ache', 'acl', 'aco', 'acted', 'acting', 'action', 'activate', 'active', 'activity', 'actor', 'actual', 'actually', 'ad', 'adam', 'add', 'addamsfa', 'added', 'addicted', 'addie', 'address', 'admin', 'administrator', 'admirer', 'admit', 'adore', 'adoring', 'adult', 'advance', 'adventure', 'advice', 'advise', 'ae', 'aeronautics', 'aeroplane', 'affair', 'affection', 'afraid', 'aft', 'afternoon', 'aftr', 'ag', 'agalla', 'age', 'agent', 'ago', 'agree', 'ah', 'aha', 'ahead', 'ahmad', 'aid', 'aight', 'ain', 'aint', 'air', 'airport', 'airtel', 'aiya', 'aiyah', 'aiyar', 'aiyo', 'aj', 'aka', 'al', 'alaipayuthe', 'album', 'alcohol', 'alert', 'alex', 'alfie', 'algarve', 'ali', 'alive', 'allah', 'allow', 'allowed', 'alright', 'alrite', 'alwys', 'amazing', 'american', 'amp', 'amt', 'amused', 'amy', 'andros', 'angry', 'animation', 'anna', 'annie', 'anniversary', 'announcement', 'annoying', 'anot', 'ansr', 'answer', 'answered', 'answering', 'anthony', 'anti', 'anybody', 'anymore', 'anythin', 'anytime', 'anyways', 'aom', 'apart', 'apartment', 'apo', 'apologise', 'app', 'apparently', 'apple', 'applebees', 'application', 'apply', 'appointment', 'appreciate', 'appreciated', 'approx', 'apps', 'appt', 'april', 'aproach', 'ar', 'arcade', 'ard', 'area', 'aren', 'arent', 'argh', 'argue', 'argument', 'arm', 'armand', 'arng', 'arrange', 'arrested', 'arrive', 'arsenal', 'art', 'arun', 'asap', 'ashley', 'ask', 'askd', 'asked', 'askin', 'asking', 'asks', 'asleep', 'asp', 'assume', 'ate', 'atlanta', 'atlast', 'atm', 'attached', 'attempt', 'attend', 'auction', 'audition', 'audrey', 'august', 'aunt', 'aunty', 'auto', 'av', 'available', 'avatar', 'ave', 'avent', 'avoid', 'avoiding', 'await', 'awaiting', 'awake', 'award', 'awarded', 'away', 'awesome', 'aww', 'ayn', 'ba', 'babe', 'baby', 'bad', 'bag', 'bahamas', 'bak', 'balance', 'ball', 'bang', 'bank', 'bar', 'barely', 'base', 'basic', 'basically', 'bat', 'batch', 'bath', 'bathe', 'bathing', 'battery', 'battle', 'bay', 'bb', 'bbd', 'bc', 'bck', 'bcm', 'bcoz', 'bcums', 'bday', 'bear', 'beautiful', 'beauty', 'bec', 'becoz', 'bed', 'bedrm', 'bedroom', 'beer', 'befor', 'beg', 'begging', 'begin', 'behave', 'bein', 'believe', 'belive', 'bell', 'belly', 'belovd', 'beloved', 'ben', 'beneath', 'beneficiary', 'benefit', 'best', 'bet', 'better', 'beware', 'bf', 'bhaji', 'bid', 'big', 'bigger', 'biggest', 'billed', 'billion', 'bin', 'biola', 'bird', 'birla', 'birth', 'birthdate', 'birthday', 'bishan', 'bit', 'bitch', 'bite', 'biz', 'bk', 'black', 'blackberry', 'blah', 'blake', 'blame', 'blank', 'blanket', 'bleh', 'bless', 'blessed', 'blessing', 'blind', 'block', 'bloke', 'blonde', 'bloo', 'blood', 'bloody', 'bloomberg', 'blow', 'blu', 'blue', 'bluetooth', 'bluff', 'blur', 'bmw', 'boat', 'body', 'bold', 'bone', 'bonus', 'boo', 'book', 'booked', 'booking', 'boost', 'booty', 'bootydelious', 'bored', 'borin', 'boring', 'born', 'borrow', 'bos', 'boston', 'bother', 'bottle', 'bought', 'bout', 'bowl', 'box', 'boy', 'boye', 'boyfriend', 'boytoy', 'bp', 'brah', 'brain', 'brand', 'brandy', 'bray', 'bread', 'break', 'breath', 'breathe', 'brief', 'bright', 'brilliant', 'bring', 'bringing', 'brings', 'bristol', 'british', 'britney', 'bro', 'broad', 'broke', 'broken', 'bros', 'brothas', 'brother', 'brought', 'brownie', 'bruce', 'bruv', 'bslvyl', 'bstfrnd', 'bt', 'btw', 'buck', 'bud', 'buddy', 'budget', 'buff', 'buffet', 'bugis', 'build', 'building', 'bulb', 'bun', 'burger', 'burn', 'burning', 'bus', 'business', 'busy', 'butt', 'buy', 'buyer', 'buying', 'buzy', 'buzz', 'bx', 'bye', 'cabin', 'cafe', 'cake', 'cal', 'calculation', 'cali', 'calicut', 'california', 'callback', 'callcost', 'calld', 'called', 'caller', 'callertune', 'callfreefone', 'callin', 'calling', 'calm', 'cam', 'camcorder', 'came', 'camera', 'campus', 'canada', 'canal', 'canary', 'cancel', 'cancelled', 'cancer', 'cann', 'capital', 'cappuccino', 'captain', 'car', 'card', 'cardiff', 'care', 'cared', 'career', 'careful', 'carefully', 'caring', 'carlos', 'caroline', 'carry', 'cartoon', 'case', 'cash', 'cashbin', 'cashto', 'castor', 'cat', 'catch', 'catching', 'caught', 'cause', 'causing', 'cbe', 'cc', 'cd', 'cdgt', 'celeb', 'celebrate', 'celebration', 'cell', 'center', 'centre', 'certainly', 'ch', 'cha', 'chain', 'challenge', 'chance', 'change', 'changed', 'channel', 'character', 'charge', 'charged', 'charity', 'charles', 'chart', 'chase', 'chasing', 'chat', 'chatting', 'cheap', 'cheaper', 'cheat', 'cheating', 'chechi', 'check', 'checked', 'checking', 'cheer', 'chennai', 'chicken', 'chikku', 'child', 'childish', 'chill', 'chillin', 'china', 'chinese', 'choice', 'choose', 'chosen', 'christmas', 'church', 'cine', 'cinema', 'citizen', 'city', 'claim', 'claire', 'class', 'clean', 'cleaning', 'clear', 'cleared', 'click', 'clock', 'clos', 'close', 'closed', 'closer', 'club', 'cm', 'cn', 'cock', 'code', 'coffee', 'coin', 'cold', 'colleague', 'collect', 'collected', 'collecting', 'collection', 'college', 'colour', 'com', 'come', 'comedy', 'comin', 'coming', 'common', 'community', 'comp', 'company', 'competition', 'complete', 'completely', 'complimentary', 'computer', 'comuk', 'concentrate', 'concert', 'condition', 'confidence', 'confirm', 'confirmed', 'congrats', 'congratulation', 'connect', 'connection', 'considering', 'constantly', 'contact', 'contacted', 'content', 'contract', 'convey', 'cook', 'cooking', 'cool', 'copy', 'cornwall', 'correct', 'cost', 'costa', 'couldn', 'count', 'country', 'couple', 'course', 'cover', 'coz', 'cr', 'crab', 'crack', 'cramp', 'crave', 'crazy', 'cream', 'created', 'credit', 'credited', 'creepy', 'cricketer', 'crisis', 'crore', 'cross', 'croydon', 'cruise', 'csbcm', 'csh', 'ctxt', 'cud', 'cuddle', 'cuddling', 'cum', 'cup', 'curious', 'current', 'currently', 'curry', 'cust', 'custcare', 'custom', 'customer', 'cut', 'cute', 'cutefrnd', 'cuz', 'cw', 'da', 'dad', 'daddy', 'dai', 'daily', 'damn', 'dare', 'dark', 'darlin', 'darling', 'darren', 'dat', 'date', 'datebox', 'dating', 'datz', 'dave', 'day', 'dead', 'deal', 'dear', 'dearer', 'dearly', 'death', 'december', 'decide', 'decided', 'decimal', 'decision', 'deep', 'def', 'definitely', 'del', 'deleted', 'deliver', 'delivered', 'deliveredtomorrow', 'delivery', 'dem', 'den', 'depends', 'derek', 'dey', 'di', 'diamond', 'dick', 'dictionary', 'did', 'didn', 'didnt', 'die', 'died', 'diet', 'diff', 'difference', 'different', 'difficult', 'dificult', 'digital', 'dignity', 'din', 'dinner', 'dint', 'direct', 'directly', 'dirty', 'dis', 'discount', 'discus', 'dislike', 'display', 'distance', 'disturb', 'dload', 'dnt', 'doc', 'doctor', 'doe', 'doesn', 'doesnt', 'dog', 'dogging', 'doggy', 'doin', 'doing', 'dollar', 'don', 'dont', 'door', 'dot', 'double', 'download', 'downloads', 'draw', 'dream', 'dress', 'dressed', 'dresser', 'drink', 'drinking', 'drive', 'drivin', 'driving', 'drop', 'dropped', 'drug', 'drunk', 'dry', 'dsn', 'dubsack', 'dude', 'dun', 'dunno', 'dvd', 'ear', 'earlier', 'early', 'earth', 'easier', 'easy', 'eat', 'eaten', 'eatin', 'eating', 'ec', 'eerie', 'effect', 'egg', 'eh', 'em', 'email', 'embarassed', 'end', 'ended', 'ending', 'enemy', 'energy', 'eng', 'england', 'english', 'enjoy', 'enjoyed', 'enter', 'entered', 'entitled', 'entry', 'enuff', 'envelope', 'er', 'erm', 'error', 'escape', 'ese', 'especially', 'esplanade', 'essential', 'euro', 'eve', 'evening', 'event', 'everybody', 'evn', 'evng', 'evry', 'ex', 'exact', 'exactly', 'exam', 'excellent', 'exciting', 'excuse', 'exe', 'executive', 'exhausted', 'expect', 'expecting', 'expensive', 'experience', 'expires', 'explain', 'express', 'extra', 'eye', 'fa', 'face', 'facebook', 'fact', 'failed', 'fair', 'fall', 'family', 'fan', 'fancy', 'fantastic', 'fantasy', 'far', 'farm', 'fast', 'faster', 'fat', 'father', 'fathima', 'fault', 'fave', 'favor', 'favour', 'favourite', 'fb', 'fear', 'feb', 'february', 'fee', 'feel', 'feelin', 'feeling', 'fell', 'felt', 'female', 'fetch', 'fever', 'fight', 'fighting', 'fightng', 'figure', 'file', 'film', 'final', 'finally', 'fine', 'finger', 'finish', 'finished', 'finishing', 'fish', 'fit', 'fix', 'fixed', 'fl', 'flag', 'flaked', 'flash', 'flat', 'flight', 'flirt', 'floor', 'flower', 'fly', 'fml', 'follow', 'followed', 'following', 'fone', 'food', 'fool', 'foot', 'football', 'footprint', 'force', 'foreign', 'forever', 'forevr', 'forget', 'forgot', 'form', 'forum', 'forward', 'forwarded', 'fr', 'fran', 'freak', 'free', 'freefone', 'freemsg', 'freephone', 'freezing', 'fren', 'frens', 'fri', 'friday', 'friend', 'friendship', 'frm', 'frnd', 'frnds', 'frndship', 'frog', 'fromm', 'frying', 'fuck', 'fucked', 'fuckin', 'fucking', 'ful', 'fullonsms', 'fun', 'function', 'funeral', 'funk', 'funky', 'funny', 'furniture', 'future', 'fwd', 'fyi', 'ga', 'gain', 'gal', 'galileo', 'game', 'gamestar', 'ganesh', 'gang', 'gap', 'garage', 'garbage', 'garden', 'gardener', 'gary', 'gas', 'gastroenteritis', 'gautham', 'gave', 'gay', 'gaytextbuddy', 'gb', 'gbp', 'gd', 'ge', 'gee', 'geeee', 'geeeee', 'gender', 'generally', 'genius', 'gent', 'gentle', 'gentleman', 'gently', 'genuine', 'george', 'germany', 'getstop', 'gettin', 'getting', 'getzed', 'geva', 'gf', 'ghost', 'gift', 'gim', 'girl', 'girlfrnd', 'giv', 'given', 'giving', 'glad', 'gm', 'gn', 'goal', 'god', 'goin', 'going', 'gon', 'gona', 'gone', 'good', 'goodmorning', 'goodnight', 'goodnite', 'google', 'gorgeous', 'gossip', 'got', 'goto', 'govt', 'gr', 'grahmbell', 'gram', 'grand', 'gravity', 'great', 'green', 'greet', 'greeting', 'grin', 'grl', 'ground', 'group', 'gt', 'guaranteed', 'gud', 'gudnite', 'guess', 'guide', 'guilty', 'guy', 'gym', 'ha', 'haf', 'haha', 'hahaha', 'hai', 'hair', 'haiz', 'half', 'halloween', 'ham', 'hand', 'handed', 'handle', 'handset', 'hanging', 'happen', 'happend', 'happened', 'happening', 'happens', 'happiness', 'happy', 'hard', 'hardcore', 'harry', 'hasn', 'hate', 'hav', 'haven', 'havent', 'havin', 'having', 'havnt', 'head', 'headache', 'hear', 'heard', 'heart', 'heavy', 'hee', 'height', 'helen', 'hell', 'hella', 'hello', 'help', 'hey', 'hg', 'hi', 'hide', 'high', 'hill', 'hint', 'hip', 'history', 'hit', 'hiya', 'hl', 'hmm', 'hmmm', 'hmv', 'ho', 'hold', 'holder', 'holding', 'holiday', 'holla', 'hols', 'home', 'homeowner', 'hon', 'honey', 'honeybee', 'hook', 'hop', 'hope', 'hopefully', 'hoping', 'horny', 'horrible', 'hospital', 'hostel', 'hot', 'hotel', 'hour', 'house', 'hows', 'howz', 'hp', 'hr', 'http', 'hubby', 'hug', 'huh', 'hun', 'hungry', 'hunny', 'hurry', 'hurt', 'husband', 'hv', 'hw', 'iam', 'ibhltd', 'ibiza', 'ic', 'ice', 'id', 'idea', 'identifier', 'idiot', 'idk', 'ignore', 'ikea', 'il', 'ill', 'im', 'imagine', 'imma', 'immediately', 'important', 'impossible', 'inch', 'incident', 'include', 'including', 'inclusive', 'india', 'indian', 'infernal', 'info', 'inform', 'information', 'informed', 'inning', 'insha', 'inside', 'instantly', 'instead', 'instituitions', 'instruction', 'insurance', 'intelligent', 'intention', 'interested', 'interesting', 'interflora', 'internet', 'interview', 'intro', 'invader', 'invest', 'invite', 'invited', 'inviting', 'invnted', 'iouri', 'ip', 'ipad', 'ipod', 'iq', 'irritates', 'irritating', 'iscoming', 'ish', 'island', 'isn', 'isnt', 'issue', 'italian', 'itcould', 'item', 'itwhichturnedinto', 'itz', 'ive', 'iz', 'izzit', 'ja', 'jacket', 'jackpot', 'jada', 'james', 'jamster', 'jan', 'jane', 'january', 'japanese', 'jas', 'jason', 'java', 'jay', 'jaya', 'jazz', 'jd', 'jealous', 'jean', 'jen', 'jenny', 'jerry', 'jess', 'jesus', 'jhl', 'jia', 'jiayin', 'jiu', 'jo', 'joanna', 'job', 'jogging', 'john', 'join', 'joined', 'joining', 'joke', 'jokin', 'joking', 'jolly', 'jolt', 'jordan', 'journey', 'joy', 'jsco', 'jst', 'jstfrnd', 'jsut', 'juan', 'juicy', 'july', 'june', 'jus', 'just', 'juz', 'kadeem', 'kaiez', 'kallis', 'kano', 'kappa', 'karaoke', 'kate', 'kavalan', 'kay', 'kb', 'ke', 'keeping', 'kegger', 'kent', 'kept', 'kerala', 'keralacircle', 'kettoda', 'key', 'kg', 'kick', 'kickoff', 'kid', 'kidding', 'kidz', 'kill', 'killed', 'killing', 'kind', 'kinda', 'kindly', 'king', 'kiosk', 'kiss', 'kl', 'knackered', 'knee', 'knew', 'knock', 'know', 'knowing', 'knw', 'konw', 'kothi', 'kr', 'kudi', 'kusruthi', 'kz', 'la', 'lab', 'lac', 'lady', 'lag', 'laid', 'land', 'landline', 'lane', 'langport', 'language', 'laptop', 'lar', 'largest', 'late', 'lately', 'later', 'latest', 'latr', 'laugh', 'laughed', 'laughing', 'laundry', 'law', 'lay', 'lazy', 'lccltd', 'ldew', 'ldn', 'ldnw', 'le', 'lead', 'leaf', 'learn', 'leave', 'leaving', 'lect', 'lecture', 'left', 'leg', 'legal', 'leh', 'lei', 'lem', 'length', 'leona', 'lesson', 'let', 'letter', 'lf', 'liao', 'lib', 'library', 'lick', 'lido', 'lie', 'life', 'lifetime', 'lifpartnr', 'lift', 'light', 'lik', 'like', 'liked', 'likely', 'lil', 'lily', 'limit', 'limiting', 'line', 'linerental', 'link', 'lion', 'lionm', 'lionp', 'lip', 'list', 'listen', 'listening', 'literally', 'little', 'live', 'lived', 'liverpool', 'living', 'lk', 'll', 'lmao', 'lo', 'load', 'loan', 'local', 'location', 'lock', 'log', 'login', 'logo', 'lol', 'london', 'lonely', 'long', 'longer', 'look', 'lookatme', 'looked', 'lookin', 'looking', 'loose', 'lor', 'lose', 'loses', 'losing', 'loss', 'lost', 'lot', 'lotr', 'lotta', 'lou', 'loud', 'lounge', 'lousy', 'lov', 'lovable', 'love', 'loved', 'lovejen', 'lovely', 'loveme', 'lover', 'loverboy', 'loving', 'lovingly', 'low', 'lower', 'loxahatchee', 'loyal', 'loyalty', 'lp', 'lst', 'lt', 'lttrs', 'luck', 'lucky', 'lucozade', 'lucy', 'lunch', 'lush', 'luv', 'luvs', 'lux', 'luxury', 'lv', 'lvblefrnd', 'lyf', 'lyfu', 'lyk', 'ma', 'maangalyam', 'mac', 'machan', 'macho', 'mad', 'madam', 'mag', 'maga', 'magical', 'mah', 'mahal', 'maid', 'mail', 'mailbox', 'main', 'maintain', 'major', 'make', 'makin', 'making', 'malaria', 'male', 'mall', 'man', 'manage', 'managed', 'management', 'manda', 'mandan', 'maneesha', 'map', 'march', 'margaret', 'mark', 'market', 'marriage', 'married', 'marrow', 'marry', 'massage', 'massive', 'master', 'match', 'mate', 'math', 'mathematics', 'matrix', 'matter', 'matured', 'maturity', 'max', 'maximize', 'mayb', 'maybe', 'mb', 'mca', 'mcat', 'meal', 'mean', 'meaning', 'meant', 'measure', 'med', 'medical', 'medicine', 'meet', 'meetin', 'meeting', 'mega', 'meh', 'mei', 'mel', 'melle', 'melt', 'member', 'membership', 'memory', 'men', 'mental', 'menu', 'meow', 'merry', 'mesages', 'mess', 'message', 'messaged', 'messaging', 'messenger', 'messy', 'met', 'mi', 'mid', 'middle', 'midnight', 'mids', 'mila', 'mile', 'milk', 'million', 'min', 'mind', 'mini', 'minimum', 'minmobsmorelkpobox', 'minmoremobsemspobox', 'minnaminunginte', 'minor', 'minute', 'minuts', 'miracle', 'misbehaved', 'miserable', 'miss', 'missed', 'missin', 'missing', 'mistake', 'mite', 'mitsake', 'mix', 'mk', 'ml', 'mm', 'mmm', 'mmmm', 'mmmmm', 'mmmmmm', 'mnth', 'mnths', 'mo', 'moan', 'mob', 'mobile', 'mobilesdirect', 'mobileupd', 'mobno', 'moby', 'mode', 'model', 'module', 'moji', 'mojibiola', 'mokka', 'mom', 'moment', 'mon', 'monday', 'money', 'monkey', 'mono', 'month', 'monthly', 'mood', 'moon', 'moral', 'morefrmmob', 'morn', 'mornin', 'morning', 'moro', 'morow', 'morphine', 'morro', 'morrow', 'mother', 'motorola', 'mountain', 'mouth', 'moved', 'movie', 'movietrivia', 'moving', 'mp', 'mr', 'mrng', 'mrt', 'mrw', 'msg', 'msging', 'msgrcvd', 'msgrcvdhg', 'msn', 'mt', 'mtalk', 'mth', 'mths', 'mtmsg', 'mtmsgrcvd', 'mu', 'muah', 'mum', 'mummy', 'mumtaz', 'munsters', 'murder', 'murdered', 'murderer', 'music', 'musthu', 'muz', 'mystery', 'na', 'nag', 'nagar', 'nah', 'nahi', 'naked', 'nalla', 'named', 'nan', 'nanny', 'nap', 'nasdaq', 'nasty', 'nat', 'natalie', 'natalja', 'national', 'natural', 'nature', 'naughty', 'nb', 'nd', 'ne', 'near', 'nearly', 'necessarily', 'necessary', 'neck', 'necklace', 'ned', 'need', 'needed', 'neft', 'neighbor', 'neighbour', 'nervous', 'net', 'netcollex', 'network', 'networking', 'neva', 'new', 'neway', 'newest', 'news', 'ni', 'nic', 'nice', 'nichols', 'nigeria', 'night', 'nimya', 'nit', 'nite', 'nitros', 'noe', 'nok', 'nokia', 'nokias', 'noline', 'noon', 'nope', 'norm', 'normal', 'normally', 'northampton', 'note', 'nothin', 'notice', 'notxt', 'noun', 'nowadays', 'nt', 'ntt', 'ntwk', 'nu', 'num', 'number', 'nurungu', 'nuther', 'nvm', 'nw', 'nxt', 'ny', 'nyc', 'nydc', 'nyt', 'obviously', 'occupy', 'odi', 'offer', 'office', 'official', 'officially', 'ofice', 'oh', 'oi', 'oic', 'oil', 'ok', 'okay', 'okey', 'okie', 'ola', 'old', 'omg', 'omw', 'oni', 'onion', 'online', 'onwards', 'oooh', 'oops', 'open', 'opening', 'operator', 'opinion', 'opportunity', 'opt', 'option', 'optout', 'orange', 'orchard', 'order', 'ordered', 'oredi', 'oreo', 'orig', 'original', 'oru', 'oso', 'otside', 'outage', 'outside', 'outstanding', 'outta', 'ovulation', 'ow', 'owns', 'oz', 'pa', 'pack', 'package', 'page', 'paid', 'pain', 'painful', 'painting', 'pale', 'pan', 'pandy', 'panic', 'pap', 'paper', 'paperwork', 'paragon', 'parco', 'parent', 'paris', 'park', 'parked', 'parking', 'partner', 'partnership', 'party', 'pas', 'passed', 'passionate', 'password', 'past', 'path', 'pattern', 'patty', 'pay', 'payed', 'payee', 'paying', 'payment', 'payoh', 'pc', 'peace', 'peaceful', 'peak', 'pee', 'pen', 'pending', 'penis', 'penny', 'people', 'percent', 'perfect', 'period', 'permission', 'person', 'personal', 'personality', 'perwksub', 'pete', 'petey', 'petrol', 'pg', 'ph', 'philosophy', 'phne', 'phoenix', 'phone', 'phoned', 'photo', 'php', 'pic', 'pick', 'picked', 'picking', 'pickle', 'picsfree', 'picture', 'pie', 'piece', 'pig', 'pilate', 'pimple', 'pin', 'pink', 'piss', 'pissed', 'pix', 'pizza', 'place', 'placement', 'plan', 'plane', 'planet', 'planned', 'planning', 'play', 'played', 'player', 'playing', 'plaza', 'pleased', 'pleasure', 'plenty', 'plm', 'pls', 'plus', 'plz', 'pm', 'po', 'pobox', 'pocketbabe', 'pod', 'poem', 'point', 'poker', 'pole', 'police', 'politician', 'polo', 'poly', 'polyh', 'polyph', 'polyphonic', 'polys', 'pongal', 'pool', 'poop', 'poor', 'pop', 'popcorn', 'popped', 'porn', 'position', 'possession', 'possible', 'post', 'postcard', 'postcode', 'posted', 'potato', 'potential', 'potter', 'pouch', 'pound', 'pours', 'pout', 'power', 'pp', 'ppermesssubscription', 'ppl', 'pple', 'ppm', 'ppmx', 'ppw', 'prabha', 'practical', 'practice', 'practicing', 'pray', 'praying', 'pre', 'prefer', 'preferably', 'prem', 'premier', 'premium', 'prepaid', 'prepare', 'prepared', 'prepayment', 'prescription', 'present', 'press', 'pretty', 'previous', 'previously', 'prey', 'price', 'pride', 'prince', 'princess', 'print', 'printed', 'priscilla', 'privacy', 'private', 'prize', 'pro', 'prob', 'probably', 'problem', 'probs', 'process', 'processed', 'prof', 'professor', 'profile', 'profit', 'program', 'project', 'prolly', 'promise', 'promo', 'prompt', 'proof', 'properly', 'property', 'propose', 'propsd', 'prospect', 'protect', 'prove', 'proverb', 'provided', 'pt', 'ptbo', 'pub', 'public', 'pull', 'purchase', 'purity', 'purpose', 'purse', 'push', 'pussy', 'puttin', 'putting', 'pw', 'px', 'qatar', 'qp', 'qu', 'quality', 'queen', 'ques', 'question', 'questioned', 'quick', 'quickly', 'quiet', 'quit', 'quite', 'quiz', 'quote', 'quoting', 'qxj', 'racing', 'radio', 'raed', 'rael', 'railway', 'rain', 'raining', 'raise', 'raj', 'raji', 'rakhesh', 'rally', 'ran', 'random', 'randomly', 'randy', 'rang', 'range', 'ranjith', 'rate', 'ray', 'rcv', 'rcvd', 'rd', 'reach', 'reached', 'reaching', 'reaction', 'read', 'reader', 'reading', 'ready', 'real', 'realise', 'reality', 'realize', 'realized', 'really', 'realy', 'reason', 'reasonable', 'reboot', 'rec', 'recd', 'receipt', 'receive', 'receivea', 'received', 'receiving', 'recent', 'recently', 'recession', 'recharge', 'reckon', 'recognise', 'record', 'recovery', 'red', 'redeemed', 'reduce', 'ref', 'reference', 'refilled', 'refused', 'reg', 'regard', 'regarding', 'register', 'registered', 'regret', 'regular', 'relation', 'relative', 'relax', 'released', 'rem', 'remain', 'remains', 'remember', 'remembered', 'remembr', 'remind', 'reminder', 'reminding', 'removal', 'remove', 'removed', 'renewal', 'rent', 'rental', 'rentl', 'repair', 'repeat', 'replace', 'replacement', 'replied', 'reply', 'replying', 'report', 'representative', 'request', 'research', 'reserve', 'respect', 'respectful', 'responce', 'respond', 'responding', 'response', 'responsibility', 'rest', 'restaurant', 'result', 'resume', 'retrieve', 'return', 'returned', 'reveal', 'revealed', 'reverse', 'review', 'revision', 'reward', 'rewarding', 'rg', 'rgds', 'rhythm', 'rice', 'rich', 'ride', 'right', 'rightly', 'ring', 'ringtone', 'ringtoneking', 'ringtones', 'risk', 'rite', 'river', 'road', 'roast', 'rock', 'rofl', 'roger', 'role', 'romantic', 'ron', 'room', 'roommate', 'rose', 'round', 'row', 'royal', 'rply', 'rr', 'rstm', 'ru', 'rub', 'rude', 'ruin', 'ruining', 'rule', 'rum', 'rumour', 'run', 'running', 'rush', 'rw', 'ryan', 'sac', 'sachin', 'sacrifice', 'sad', 'sae', 'safe', 'said', 'sake', 'salam', 'salary', 'sale', 'salon', 'sam', 'santa', 'sar', 'sarasota', 'sarcasm', 'sarcastic', 'sary', 'sat', 'sathya', 'satisfied', 'satisfy', 'saturday', 'saucy', 'savamob', 'save', 'saved', 'saw', 'say', 'saying', 'scared', 'scary', 'sch', 'schedule', 'school', 'science', 'scold', 'score', 'scoring', 'scotch', 'scotland', 'scotsman', 'scream', 'screamed', 'screaming', 'screen', 'scrounge', 'sd', 'se', 'sea', 'search', 'searching', 'season', 'seat', 'sec', 'second', 'secret', 'secretary', 'secretly', 'section', 'sed', 'seed', 'seeing', 'seen', 'select', 'selected', 'selection', 'self', 'selfish', 'sell', 'selling', 'sem', 'semester', 'sen', 'send', 'sender', 'sending', 'sends', 'sense', 'sensitive', 'sent', 'sentence', 'senthil', 'sept', 'series', 'seriously', 'service', 'serving', 'set', 'setting', 'settle', 'settled', 'seven', 'sex', 'sexy', 'sh', 'sha', 'shagged', 'shahjahan', 'shall', 'shame', 'shampain', 'share', 'shared', 'sharing', 'shd', 'sheet', 'sheffield', 'shelf', 'shesil', 'shijas', 'shining', 'ship', 'shipped', 'shipping', 'shirt', 'shit', 'shitload', 'shld', 'shock', 'shocking', 'shoe', 'shoot', 'shop', 'shoppin', 'shopping', 'shore', 'short', 'shortage', 'shorter', 'shortly', 'shot', 'shouldn', 'shouted', 'shoving', 'shower', 'showing', 'shracomorsglsuplt', 'shu', 'shuhui', 'shut', 'shy', 'si', 'sian', 'sib', 'sick', 'sigh', 'sight', 'sign', 'signing', 'silence', 'silent', 'silently', 'silver', 'sim', 'simple', 'simpler', 'simply', 'sinco', 'sing', 'singing', 'single', 'sip', 'sipix', 'sir', 'sister', 'sit', 'site', 'sitll', 'sitting', 'situation', 'siva', 'size', 'sk', 'skilgme', 'skillgame', 'skip', 'sky', 'skype', 'skyped', 'slap', 'slave', 'sleep', 'sleepin', 'sleeping', 'slept', 'slice', 'slipper', 'slow', 'slowly', 'sm', 'small', 'smart', 'smile', 'smiling', 'smoke', 'smoking', 'smth', 'sn', 'snake', 'snow', 'social', 'sofa', 'soft', 'software', 'sol', 'solve', 'somebody', 'somethin', 'song', 'sony', 'sonyericsson', 'soon', 'sooner', 'sore', 'sorrow', 'sorry', 'sort', 'sorted', 'sorting', 'sory', 'soryda', 'sound', 'soup', 'source', 'south', 'sp', 'space', 'spanish', 'spare', 'speak', 'special', 'specially', 'speechless', 'speed', 'spell', 'spend', 'spending', 'spent', 'spk', 'spl', 'spoke', 'spoken', 'spook', 'sport', 'spree', 'spring', 'sry', 'st', 'staff', 'stamp', 'stand', 'standard', 'standing', 'star', 'start', 'started', 'starting', 'starwars', 'statement', 'station', 'stay', 'staying', 'std', 'step', 'stock', 'stockport', 'stomach', 'stomp', 'stone', 'stop', 'stopped', 'stoptxt', 'store', 'storming', 'story', 'str', 'straight', 'stranger', 'street', 'stress', 'stretch', 'strike', 'strip', 'strong', 'stuck', 'student', 'study', 'studying', 'stuff', 'stupid', 'style', 'stylish', 'sub', 'subpoly', 'subscribe', 'subscribed', 'subscriber', 'subscription', 'successful', 'successfully', 'suck', 'sugar', 'suggest', 'suite', 'sum', 'summer', 'sun', 'sunday', 'sunny', 'sunshine', 'suntec', 'sup', 'super', 'superb', 'superior', 'supervisor', 'supply', 'support', 'supposed', 'suprman', 'sura', 'sure', 'surely', 'surfing', 'surprise', 'surprised', 'sw', 'sweet', 'sweetest', 'swimming', 'swing', 'switch', 'swt', 'swtheart', 'symbol', 'ta', 'table', 'tablet', 'taken', 'takin', 'taking', 'talent', 'talk', 'talking', 'tampa', 'tape', 'tariff', 'tat', 'taunton', 'taylor', 'tb', 'tc', 'tcr', 'tea', 'teach', 'teacher', 'team', 'tear', 'tease', 'teasing', 'technical', 'teeth', 'tel', 'tell', 'telling', 'telphone', 'temp', 'temple', 'tenant', 'tenerife', 'term', 'terrible', 'tessy', 'test', 'text', 'textcomp', 'texted', 'texting', 'textoperator', 'textpod', 'tf', 'th', 'thangam', 'thank', 'thanks', 'thanksgiving', 'thanx', 'thats', 'theatre', 'themob', 'theory', 'thing', 'think', 'thinkin', 'thinking', 'thk', 'thm', 'thnk', 'tho', 'thought', 'threat', 'throat', 'throw', 'tht', 'thts', 'thurs', 'thursday', 'ti', 'tick', 'ticket', 'tihs', 'til', 'till', 'time', 'timing', 'tired', 'tirupur', 'title', 'tkts', 'tlp', 'tm', 'tmr', 'tncs', 'toa', 'toclaim', 'today', 'tog', 'told', 'toll', 'tom', 'tomarrow', 'tomo', 'tomorrow', 'tone', 'tonight', 'tonite', 'took', 'torch', 'tot', 'total', 'totally', 'touch', 'touched', 'tough', 'tour', 'town', 'track', 'trade', 'traffic', 'train', 'training', 'transaction', 'transfer', 'transfered', 'travel', 'treat', 'treated', 'tree', 'tried', 'trip', 'trouble', 'truck', 'true', 'truffle', 'truly', 'trust', 'truth', 'try', 'trying', 'tsandcs', 'tscs', 'tsunami', 'tt', 'ttyl', 'tues', 'tuesday', 'tuition', 'turn', 'tv', 'twice', 'txt', 'txtauction', 'txtin', 'txting', 'txts', 'tyler', 'type', 'tyrone', 'ubi', 'ugh', 'uk', 'umma', 'ummmmmaah', 'unable', 'uncle', 'understand', 'understanding', 'understood', 'uni', 'unique', 'university', 'unless', 'unlimited', 'unredeemed', 'unsold', 'unsub', 'unsubscribe', 'update', 'upgrade', 'upload', 'upset', 'upto', 'ur', 'urawinner', 'ure', 'urgent', 'urgently', 'urgnt', 'url', 'urn', 'urself', 'usc', 'use', 'used', 'user', 'usf', 'using', 'usual', 'usually', 'uz', 'vaazhthukkal', 'vale', 'valentine', 'valid', 'valuable', 'value', 'valued', 'various', 'vary', 'vava', 'vday', 've', 'vega', 'vegetable', 'verified', 'verify', 'version', 'vettam', 'vewy', 'vid', 'video', 'videochat', 'videophones', 'vijay', 'vikky', 'village', 'violated', 'violence', 'violet', 'vip', 'virgin', 'visionsms', 'visit', 'visitor', 'viva', 'vivek', 'vl', 'voda', 'vodafone', 'vodka', 'voice', 'voicemail', 'vomit', 'vomiting', 'vote', 'voucher', 'vry', 'vth', 'vu', 'wa', 'wah', 'waheed', 'waht', 'wait', 'waited', 'waitin', 'waiting', 'wake', 'waking', 'wale', 'walk', 'walked', 'walking', 'wall', 'wallpaper', 'walmart', 'wan', 'wana', 'want', 'wanted', 'wanting', 'wap', 'warm', 'warner', 'warning', 'warranty', 'wasn', 'waste', 'wasted', 'wat', 'watch', 'watching', 'water', 'watever', 'wating', 'wats', 'wave', 'waxsto', 'way', 'wb', 'wc', 'weak', 'weakness', 'wear', 'wearing', 'weather', 'web', 'website', 'wed', 'wedding', 'wednesday', 'wee', 'weed', 'week', 'weekend', 'weekly', 'weigh', 'weight', 'weird', 'weirdest', 'welcome', 'welp', 'wen', 'went', 'wer', 'wesley', 'west', 'westlife', 'wet', 'whats', 'whatsup', 'whenevr', 'white', 'whn', 'whr', 'wicklow', 'wid', 'widelive', 'wif', 'wife', 'wifi', 'wihtuot', 'wil', 'willing', 'win', 'winaweek', 'winawk', 'wind', 'window', 'wine', 'winner', 'winning', 'wipro', 'wisdom', 'wise', 'wish', 'wishin', 'wishing', 'wiskey', 'wit', 'wiv', 'wk', 'wkend', 'wkent', 'wkg', 'wkly', 'wks', 'wld', 'wml', 'wn', 'wnt', 'wo', 'woke', 'woken', 'woman', 'won', 'wonder', 'wonderful', 'wondering', 'wont', 'woot', 'word', 'work', 'workin', 'working', 'world', 'worried', 'worry', 'worse', 'worst', 'worth', 'wot', 'woulda', 'wouldn', 'wow', 'wp', 'wq', 'wrc', 'write', 'wrk', 'wrnog', 'wrong', 'wrote', 'wt', 'wtf', 'wu', 'wud', 'wuld', 'wun', 'www', 'wx', 'wylie', 'xam', 'xavier', 'xchat', 'xh', 'xin', 'xmas', 'xn', 'xuhui', 'xx', 'xxx', 'xxxmobilemovieclub', 'xxxx', 'xxxxx', 'xxxxxx', 'xxxxxxx', 'xxxxxxxxx', 'xy', 'ya', 'yahoo', 'yan', 'yar', 'yarasu', 'yay', 'yck', 'yeah', 'year', 'yeh', 'yelling', 'yellow', 'yep', 'yer', 'yes', 'yest', 'yesterday', 'yetunde', 'yf', 'yijue', 'ym', 'yo', 'yoga', 'yogasana', 'yor', 'youre', 'yr', 'yummy', 'yun', 'yunny', 'yuo', 'yup', 'zed', 'zindgi', 'zoe']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "max_features = 3000\n",
    "count_vectorizer = CountVectorizer(max_features = max_features, stop_words = \"english\")\n",
    "sparce_matrix = count_vectorizer.fit_transform(description_list).toarray()\n",
    "print(\"Самые часто встречаемые {} слов: {}\".format(max_features,count_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чаще всего во всех сообщениях встречается слово 'crazy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pH1JagoUelrD",
    "outputId": "40052921-4c09-4161-f91e-847e5419b63b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592\n"
     ]
    }
   ],
   "source": [
    "list_names = count_vectorizer.get_feature_names()\n",
    "for i in range(len(list_names)):\n",
    "    if list_names[i] == 'crazy':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wbDY56XWV7do"
   },
   "source": [
    "Исходные данные преобразуем в bag-of-words формат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uJB0dstJfO7J",
    "outputId": "257b248e-7c2f-43a0-b44c-180930b6e01c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparce_matrix[0, 592]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "k8yCXDOfWAww",
    "outputId": "cba53e0e-5d41-4385-8e96-a8df9ec72589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(len(sparce_matrix[0,: ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9e24S-P4Vsrr"
   },
   "outputs": [],
   "source": [
    "y = data.iloc[:,0].values\n",
    "x = sparce_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCv03et0WW5L"
   },
   "source": [
    "Делим данные на тренировочные и тестовые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rF67b7VdV2VK"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFi1KFI8WaWS"
   },
   "source": [
    "Напишем **наивный байесовский классификатор**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ls-QwJfpWNVH",
    "outputId": "9aeb4a8e-899d-4b7d-e277-c91e0f230391"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of our model: 0.8753363228699551\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "print(\"the accuracy of our model: {}\".format(nb.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "u9D5KTE6h19S",
    "outputId": "d5f5aca2-1a57-47a1-ed15-33a73a7c68eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92       966\n",
      "           1       0.52      0.89      0.66       149\n",
      "\n",
      "    accuracy                           0.88      1115\n",
      "   macro avg       0.75      0.88      0.79      1115\n",
      "weighted avg       0.92      0.88      0.89      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, nb.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hRdUt0ThWe30"
   },
   "source": [
    "Напишем логистическую регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "epQOa7FRWhqS",
    "outputId": "a27256ad-c076-4170-e7de-b8768fa35ba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our accuracy is: 0.9820627802690582\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter = 200)\n",
    "lr.fit(x_train,y_train)\n",
    "print(\"our accuracy is: {}\".format(lr.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "LNyFu4X1iabe",
    "outputId": "77ef3195-b21d-4b15-96b5-9d4595bb8d19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       966\n",
      "           1       1.00      0.87      0.93       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.93      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lr.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cWc_Fs10W71Y"
   },
   "source": [
    "Классификатор по методу ближайшего соседа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-05vUVlPW6Ey",
    "outputId": "96718b84-2014-4f48-a713-3964037917b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With KNN (K=3) accuracy is:  0.9399103139013453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(x_train,y_train)\n",
    "#print('Prediction: {}'.format(prediction))\n",
    "print('With KNN (K=3) accuracy is: ',knn.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "dIrdoC-7igLs",
    "outputId": "b2da12cd-3931-40e0-a1d9-e12002f1db1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       966\n",
      "           1       1.00      0.55      0.71       149\n",
      "\n",
      "    accuracy                           0.94      1115\n",
      "   macro avg       0.97      0.78      0.84      1115\n",
      "weighted avg       0.94      0.94      0.93      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, knn.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZSGytE8OisyJ"
   },
   "source": [
    "Из всех выбранных моделей лучше всего дала результаты модель логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u5toCBH_mp61"
   },
   "source": [
    "# Анализ текста на тональность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y-pDViybnhoU"
   },
   "source": [
    "Рассмотрим датасет twitter sentiment analyses hatred speach https://www.kaggle.com/arkhoshghalb/twitter-sentiment-analysis-hatred-speech#train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "O3EBuuYhmkVX",
    "outputId": "da6ed447-290d-4f8f-8dc7-45faa47169df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='http://yustiks.ru/dataset/twitter_train.csv'\n",
    "data=pd.read_csv(url)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cuf8Zgoujyo1",
    "outputId": "3bb4c36f-d09c-45d4-f08c-cbe7e8fbe943"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31962"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1DiMSMWyn2Fh"
   },
   "source": [
    "Есть колонка **label** - класс 1 означает, что текст содержит в себе **ненависть и расизм**. 0 - **текст нейтрален по теме**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ri6UgBXQoBnb"
   },
   "source": [
    "# Задача - определить класс, к которому относится тот или иной текст"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RnbwL_5mrS8U"
   },
   "source": [
    "Удаляем слова, которые не имеют смысловой нагрузки (например, слова 'и', 'или', 'а' и другие)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "oQvN2BL-ojtl",
    "outputId": "4ecec07f-4c6e-4234-b7fd-2c9450b24c7a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yustinaivanova/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "import re\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(line):\n",
    "    word_tokens = word_tokenize(line)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "    return \" \".join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sbMjGkOgr4QA"
   },
   "source": [
    "Далее функция, с помощью которой мы будем обрабатывать твиты\n",
    "\n",
    "\n",
    "*   переводим все слова в строчные буквы\n",
    "*   удаляем цифры\n",
    "*   удаляем пунктуацию\n",
    "*   удаляем стоп-слова\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3qfvy75XrDtU"
   },
   "outputs": [],
   "source": [
    "def preprocess(line):\n",
    "  # все слова переводим в строчный текст\n",
    "    line = line.lower()\n",
    "  # удаляем цифры\n",
    "    line = re.sub(r'\\d+', '', line)\n",
    "  # удаляем пунктуацию\n",
    "    line = line.translate(line.maketrans(\"\",\"\", string.punctuation))\n",
    "    line = remove_stopwords(line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z-I5nlmNsmpZ"
   },
   "source": [
    "Предобработка всех твитов из таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "eHtyWq8NrA8H",
    "outputId": "b34dd777-5531-4878-e459-fc4a7e76ab02"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yustinaivanova/venv/venv/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train = data\n",
    "\n",
    "for i,line in enumerate(train.tweet):\n",
    "    train.tweet[i] = preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>user father dysfunctional selfish drags kids d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>user user thanks lyft credit cant use cause do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>model love u take u time urð± ðððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate user isz youuuððððððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>see nina turner airwaves trying wrap mantle ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening sad songs monday morning otw work sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>user sikh temple vandalised calgary wso condem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank user follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "0          1      0  user father dysfunctional selfish drags kids d...\n",
       "1          2      0  user user thanks lyft credit cant use cause do...\n",
       "2          3      0                                     bihday majesty\n",
       "3          4      0  model love u take u time urð± ðððð...\n",
       "4          5      0                      factsguide society motivation\n",
       "...      ...    ...                                                ...\n",
       "31957  31958      0  ate user isz youuuððððððð...\n",
       "31958  31959      0  see nina turner airwaves trying wrap mantle ge...\n",
       "31959  31960      0    listening sad songs monday morning otw work sad\n",
       "31960  31961      1  user sikh temple vandalised calgary wso condem...\n",
       "31961  31962      0                                  thank user follow\n",
       "\n",
       "[31962 rows x 3 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JqH38PT5sb47"
   },
   "source": [
    "Разделим датасет на тренировочный и тестовый"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "xqF08sLBsapA",
    "outputId": "1cdd02bb-6a53-4d7e-e37b-3ebc683f61b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2242 entries, 13 to 31960\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      2242 non-null   int64 \n",
      " 1   label   2242 non-null   int64 \n",
      " 2   tweet   2242 non-null   object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 70.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29720 entries, 0 to 31961\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      29720 non-null  int64 \n",
      " 1   label   29720 non-null  int64 \n",
      " 2   tweet   29720 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 928.8+ KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train['tweet'], train['label'], \n",
    "                                                    test_size=0.5, stratify=train['label'])\n",
    "\n",
    "trainp=train[train.label==1]\n",
    "trainn=train[train.label==0]\n",
    "print(trainp.info())\n",
    "trainn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MEBfXJvFstxJ"
   },
   "source": [
    "Можно заметить, что классы **несбалансированы**: в классе 1 2242 элемента, а в классе 0 их 29720. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jZzvozfItINL"
   },
   "source": [
    "Создадим bag-of-words вектора для всех твитов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jNcOfFrDtNoU"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vect = CountVectorizer()\n",
    "tf_train=vect.fit_transform(X_train)  #train the vectorizer, build the vocablury\n",
    "tf_test=vect.transform(X_test)  #get same encodings on test data as of vocabulary built"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xz_uoxWUtRJl"
   },
   "source": [
    "Создадим модель **Наивный байес**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EcwwEUNHtTA7"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jdihWKR6tlbR"
   },
   "source": [
    "Обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lpthYn7htjiG",
    "outputId": "d7bfa8ba-a61f-49d5-b306-52a5d386b5b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=tf_train,y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wOKUfO3JtoKC"
   },
   "source": [
    "Посмотрим качество модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "x--lPL7Jtosu",
    "outputId": "bb7dca9f-aca6-4953-c339-d2108ae34e7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     14860\n",
      "           1       0.89      0.43      0.58      1121\n",
      "\n",
      "    accuracy                           0.96     15981\n",
      "   macro avg       0.92      0.71      0.78     15981\n",
      "weighted avg       0.95      0.96      0.95     15981\n",
      "\n",
      "[[14798    62]\n",
      " [  642   479]]\n"
     ]
    }
   ],
   "source": [
    "expected = y_test\n",
    "predicted=model.predict(tf_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e5hNKWCVtzkb"
   },
   "source": [
    "Можно заметить, что класс 1 предсказывается намного хуже, чем класс 0: класса 1 намного меньше по числу элементов, чем класс 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EkZX9ROIt_1f"
   },
   "source": [
    "Сбалансируем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "mnkYC-snuOHP",
    "outputId": "77fa6a69-6116-4913-ee62-093180fc751d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "0    29720\n",
      "1     2242\n",
      "Name: label, dtype: int64\n",
      "After\n",
      "1    29720\n",
      "0    29720\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_imbalanced = train\n",
    "from sklearn.utils import resample\n",
    "df_majority = train[train.label==0]\n",
    "df_minority = train[train.label==1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(df_majority),    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "print(\"Before\")\n",
    "print(train.label.value_counts())\n",
    "print(\"After\")\n",
    "print(df_upsampled.label.value_counts())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_upsampled['tweet'], df_upsampled['label'], test_size=0.5, stratify=df_upsampled['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QwutTun8xX2I"
   },
   "source": [
    "Можно заметить, что тренировочных данных стало больше, и классы уравнялись в количестве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "NoD2ivRazam6",
    "outputId": "a4b034e7-53ee-4349-d67d-629f48fe2188"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94     14860\n",
      "           1       0.92      0.97      0.94     14860\n",
      "\n",
      "    accuracy                           0.94     29720\n",
      "   macro avg       0.94      0.94      0.94     29720\n",
      "weighted avg       0.94      0.94      0.94     29720\n",
      "\n",
      "Матрица confusion\n",
      "[[13612  1248]\n",
      " [  458 14402]]\n"
     ]
    }
   ],
   "source": [
    "tf_train=vect.transform(X_train)\n",
    "tf_test=vect.transform(X_test)\n",
    "model.fit(X=tf_train,y=y_train)\n",
    "expected = y_test\n",
    "predicted=model.predict(tf_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print('Матрица confusion')\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GA-HqiesgQGd"
   },
   "source": [
    "Можно заметить, что балансировка привела к улучшению результата."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "4hzAP6kG0qCb",
    "J0t8bCoH8rIS"
   ],
   "include_colab_link": true,
   "name": "lecture_5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
